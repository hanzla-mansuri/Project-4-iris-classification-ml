{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Machine Learning Classification on IRIS data set\n",
    "    **This project focuses on classifying the species of the Iris flower (Setosa, Versicolor, and Virginica) using supervised machine learning techniques. The dataset includes sepal and petal length and width as features.** \n",
    "\n",
    "    Key objectives include exploratory data analysis, building classification models (e.g., Logistic Regression, Decision Trees, etc.), and evaluating model performance using metrics like accuracy and precision. The project demonstrates end-to-end implementation of a machine learning pipeline, showcasing feature engineering, model training, and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import Required Libraries:**\n",
    "Identify and import libraries such as pandas, numpy, matplotlib, seaborn, and scikit-learn for data manipulation, visualization, and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "plt.style.use('classic')\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Load the Dataset :**\n",
    "\n",
    "Load the Dataset: Load the Iris dataset, either from a built-in library (e.g., scikit-learn) or an external file (e.g., CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv('iris.csv') # Initial Import\n",
    "df_1 = df_0.drop('Id',axis=1).copy() #copy for future use & droped ID as this may impact model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Understand the Dataset:**\n",
    "\n",
    "Display the first few rows of the dataset.\n",
    "Check for null values and basic statistics (mean, median, standard deviation, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.isnull().sum() #Chek nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = df_1.Species.unique()\n",
    "species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.Exploratory Data Analysis (EDA)**\n",
    "\n",
    "Analyze the distribution of each feature (sepal length, sepal width, petal length, petal width).\n",
    "Visualize relationships between features using scatter plots, pair plots, and box plots.\n",
    "Check the class distribution for balance among the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'Species' column into numeric values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df_1['SpeciesEncoded'] = label_encoder.fit_transform(df_1['Species'])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(\n",
    "    df_1['SepalLengthCm'], \n",
    "    df_1['SepalWidthCm'], \n",
    "    c=df_1['SpeciesEncoded'],  # Use encoded values for coloring\n",
    "    cmap='viridis',           # Color map for differentiation\n",
    "    s=100,                    # Size of the points\n",
    "    alpha=0.8                 # Transparency\n",
    ")\n",
    "plt.colorbar(scatter, label='Species (Encoded)')\n",
    "plt.title('Scatter Plot of Sepal Dimensions by Species', fontsize=14)\n",
    "plt.xlabel('Sepal Length (cm)', fontsize=12)\n",
    "plt.ylabel('Sepal Width (cm)', fontsize=12)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(\n",
    "    df_1['PetalLengthCm'], \n",
    "    df_1['PetalWidthCm'], \n",
    "    c=df_1['SpeciesEncoded'],  # Use encoded values for coloring\n",
    "    cmap='viridis',           # Color map for differentiation\n",
    "    s=100,                    # Size of the points\n",
    "    alpha=0.8                 # Transparency\n",
    ")\n",
    "plt.colorbar(scatter, label='Species (Encoded)')\n",
    "plt.title('Scatter Plot of Petal Dimensions by Species', fontsize=14)\n",
    "plt.xlabel('Petal Length (cm)', fontsize=12)\n",
    "plt.ylabel('Petal Width (cm)', fontsize=12)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pair Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_1, hue= 'Species', palette='viridis', diag_kind='kde', markers=[\"o\", \"s\", \"D\"])\n",
    "plt.suptitle(\"Pair Plot of Iris Data\", y=1.02)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Finding\n",
    "plt.figure(figsize=(10, 8))\n",
    "df_1.boxplot()  # No 'ver' argument; simply call boxplot on the DataFrame\n",
    "plt.title(\"Boxplot of Features\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# Compute correlation matrix for the selected columns\n",
    "correlation_matrix = df_1[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'SpeciesEncoded']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "plt.title(\"Correlation Heatmap\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap provides a visual representation of the correlation coefficients between the numerical features in your dataset. Here's how these insights can help for a machine learning model:\n",
    "\n",
    "**Insights from the Heatmap:**\n",
    "\n",
    "Strong Correlations:\n",
    "\n",
    "PetalLengthCm and PetalWidthCm have a very high positive correlation (~0.96). This means these two features are highly redundant, and including both might not add much additional information to the model.\n",
    "SpeciesEncoded has strong correlations with PetalLengthCm (~0.95) and PetalWidthCm (~0.96), indicating these features are highly relevant for predicting the species.\n",
    "Weak Correlations:\n",
    "\n",
    "SepalWidthCm has weak or negative correlations with other features (e.g., ~-0.42 with PetalLengthCm). This suggests it might not be as informative for predicting the species compared to other features.\n",
    "Feature Selection:\n",
    "\n",
    "For models like linear regression, removing highly correlated features can help reduce multicollinearity. For instance, you might choose either PetalLengthCm or PetalWidthCm, but not both.\n",
    "Features like SepalWidthCm may require further evaluation to determine their usefulness in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame by dropping 'SepalWidthCm' and 'PetalLengthCm'\n",
    "df_2 = df_1.drop(['SepalWidthCm', 'PetalLengthCm','Species'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.Split the Dataset**\n",
    "\n",
    "Divide the dataset into training and testing sets, typically in an 80:20 or 70:30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2.drop('SpeciesEncoded',axis = 1)  # we are removing target variable\n",
    "\n",
    "#copy target into the Y\n",
    "y = df_2['SpeciesEncoded'] # Created 1 variable only for Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.Select Machine Learning Algorithms**\n",
    "\n",
    "Choose classification algorithms such as Logistic Regression, Decision Trees, Random Forests, Support Vector Machines, or K-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(X_train, y_train)\n",
    "model_LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DT = DecisionTreeClassifier()\n",
    "model_DT.fit(X_train, y_train)\n",
    "model_DT.score(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RF = RandomForestClassifier()\n",
    "model_RF.fit(X_train, y_train)\n",
    "model_RF.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_SVM = SVC()\n",
    "model_SVM.fit(X_train, y_train)\n",
    "model_SVM.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=5)  # You can tune `n_neighbors`\n",
    "model_KNN.fit(X_train, y_train)\n",
    "model_KNN.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.Evaluate the Models**\n",
    "\n",
    "Test the trained models using the testing dataset.\n",
    "Use metrics such as accuracy, precision, recall, F1-score, and confusion matrix to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#LogisticRegression\n",
    "# Predict on the test set\n",
    "y_pred = model_LR.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"LogisticRegression\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"LogisticRegression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Random Forest\n",
    "# Predict on the test set\n",
    "y_pred = model_RF.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Support Vector Machine (SVM)\n",
    "# Predict on the test set\n",
    "y_pred = model_RF.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine (SVM)\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Support Vector Machine (SVM) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#K-Nearest Neighbors (KNN)\n",
    "# Predict on the test set\n",
    "y_pred = model_KNN.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors (KNN)\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"K-Nearest Neighbors (KNN) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.Compare Model Performance**\n",
    "\n",
    "Compare the performance of different models to identify the best one for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Trying multiple models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.Visualize Results**\n",
    "\n",
    "Create plots to show model performance (e.g., accuracy scores, ROC curves).\n",
    "Visualize the confusion matrix to understand classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy Scores Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Logistic Regression', 'Random Forest', 'SVM']\n",
    "accuracy_scores = [0.93, 0.95, 0.95]\n",
    "\n",
    "# Plot the accuracy scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(model_names, accuracy_scores, color=['blue', 'green', 'orange'])\n",
    "plt.title('Model Accuracy Comparison', fontsize=14)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model_RF.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(cmap='Blues', values_format='d', xticks_rotation=45)\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.Hyperparameter Tuning**\n",
    "\n",
    "Optimize the best-performing model using techniques like Grid Search or Random Search for improved accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.Make Predictions**\n",
    "\n",
    "Use the final model to make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'SepalLengthCm': [5.9, 6.0],\n",
    "    'PetalWidthCm': [4.2, 5.1]\n",
    "})\n",
    "\n",
    "# Make predictions using the final KNN model\n",
    "predictions = model_KNN.predict(new_data)\n",
    "\n",
    "# If you want to see the probabilities for each class (if applicable)\n",
    "probabilities = model_KNN.predict_proba(new_data)\n",
    "\n",
    "# Display the results\n",
    "print(\"Predicted Classes:\", predictions)\n",
    "print(\"Prediction Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.Save the Model**\n",
    "\n",
    "Save the trained model for future using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model_KNN, 'iris_knn_model.pkl')\n",
    "print(\"Model saved as 'iris_knn_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
